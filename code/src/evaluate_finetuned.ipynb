{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17VlMTzixNqmZaJSnxsOf3ZiaHQzsQn3a","authorship_tag":"ABX9TyPMjOw+4sprGj4k98szUiq/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install import-ipynb"],"metadata":{"id":"70VevDE43VmD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/SHBT261FinalProject/code/src"],"metadata":{"id":"t2660R_j3XAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Evaluate Fine-tuned Model on TextVQA\n","Evaluates model with LoRA weights on validation/test sets\n","\"\"\"\n","\n","import os\n","import json\n","from tqdm import tqdm\n","from datetime import datetime\n","import torch\n","import numpy as np\n","\n","import import_ipynb\n","from data_loader import TextVQADataset\n","from model import load_lora_weights, get_generation_config\n","from metrics import compute_all_metrics, print_metrics"],"metadata":{"id":"GUoMYvmhmNY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_inference_finetuned(\n","    model,\n","    processor,\n","    dataset,\n","    max_samples=None,\n","    save_predictions=True,\n","    output_dir=\"results\",\n","    metric_filename=\"finetune_metric.json\",\n","    pred_filename=\"finetune_predictions.json\",\n","):\n","    model.eval()\n","    device = next(model.parameters()).device\n","\n","    predictions, ground_truths, questions_list, results = [], [], [], []\n","    num_samples = min(len(dataset), max_samples or len(dataset))\n","    gen_config = get_generation_config()\n","\n","    print(f\"\\nRunning inference on {num_samples} samples...\")\n","\n","    with torch.no_grad():\n","        for idx in tqdm(range(num_samples)):\n","            sample = dataset[idx]\n","            image = sample[\"image\"]\n","            question = sample[\"question\"]\n","            answers = sample[\"answers\"]\n","\n","            # prompt\n","            conv = [\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": [\n","                        {\"type\": \"image\"},\n","                        {\"type\": \"text\",\n","                         \"text\": f\"{question}\\nAnswer with only the exact text/number from the image.\"}\n","                    ]\n","                }\n","            ]\n","\n","            text = processor.apply_chat_template(conv, tokenize=False, add_generation_prompt=True)\n","\n","            inputs = processor(\n","                text=[text], images=[image],\n","                return_tensors=\"pt\", padding=True\n","            )\n","            inputs = {k: v.to(device) if hasattr(v, \"to\") else v for k, v in inputs.items()}\n","\n","            # Generate\n","            out_ids = model.generate(**inputs, **gen_config)\n","            input_len = inputs[\"input_ids\"].shape[1]\n","            gen_ids = out_ids[:, input_len:]\n","\n","            prediction = processor.batch_decode(gen_ids, skip_special_tokens=True)[0].strip()\n","\n","            predictions.append(prediction)\n","            ground_truths.append(answers)\n","            questions_list.append(question)\n","\n","            results.append({\n","                \"image_id\": str(sample[\"image_id\"]),\n","                \"question_id\": int(sample[\"question_id\"]),\n","                \"question\": question,\n","                \"prediction\": prediction,\n","                \"ground_truths\": answers,\n","                \"ocr_tokens\": list(sample.get(\"ocr_tokens\", [])),\n","            })\n","\n","    metrics = compute_all_metrics(predictions, ground_truths, questions_list)\n","\n","    # save outputs\n","    if save_predictions:\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        pred_path = os.path.join(output_dir, pred_filename)\n","        with open(pred_path, \"w\") as f:\n","            json.dump(results, f, indent=2, ensure_ascii=False)\n","        print(\"Predictions saved:\", pred_path)\n","\n","        metric_path = os.path.join(output_dir, metric_filename)\n","        with open(metric_path, \"w\") as f:\n","            json.dump(metrics, f, indent=2)\n","        print(\"Metrics saved:\", metric_path)\n","\n","    return {\n","        \"predictions\": predictions,\n","        \"results\": results,\n","        \"metrics\": metrics,\n","    }"],"metadata":{"id":"Er0HzQubojDY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3qp7HNN1T8tO"},"execution_count":null,"outputs":[]}]}